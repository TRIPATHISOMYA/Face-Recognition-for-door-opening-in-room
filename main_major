import os
import cv2
import sys
import pickle
import numpy as np
from PyQt5 import QtCore, QtWidgets
from PyQt5.QtCore import *
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
import MainWindow_gui
from PIL import Image
from pathlib import Path
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
import serial.tools.list_ports
import serial
import serial.tools.list_ports
import warnings
from AddPersonDialog import Ui_Dialog


class SerialPortDataProcessThread(QThread):

    def __init__(self, serialPort):
        super(SerialPortDataProcessThread, self).__init__()
        self.serialPort = serialPort


    def run(self):
        print('Opening Serial Port with properties\n\n',self.serialPort,'\n')
        self.exec_()

    def Close_Serial(self):
        print('Closing Serial Port\n')
        self.serialPort.close()

    @pyqtSlot(object)
    def writeData(self, data):
        data_encoded = data.encode("utf-8")
        self.serialPort.write(data_encoded)

class FaceSecurityML(QMainWindow, MainWindow_gui.Ui_MainWindow):

    serialWrite = QtCore.pyqtSignal(object)

    def __init__(self):
        super(FaceSecurityML,self).__init__()

        self.setupUi(self)

        self.comm_port = self.find_Arduino_Com_Port()
        self.serialArduino = serial.Serial(port=self.comm_port, baudrate=19200)
        self.SerialThread = SerialPortDataProcessThread(self.serialArduino)
        self.serialWrite.connect(self.SerialThread.writeData)

        self.addPersonButton.clicked.connect(self.addNewPersonClicked)
        self.trainButton.clicked.connect(self.trainClicked)
        self.openCameraButton.clicked.connect(self.openCameraClicked)
        self.stopCameraButton.clicked.connect(self.stopCameraClicked)
        self.takePhotoButton.clicked.connect(self.takePhotoClicked)
        self.recogniseButton.clicked.connect(self.RecogniseFace)
        self.exitButton.clicked.connect(self.exitClicked)
        self.connectButton.clicked.connect(self.OpenSerialPort)
        self.disconnectButton.clicked.connect(self.CloseSerialPort)
        self.faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
        self.recognizer = cv2.face.LBPHFaceRecognizer_create()

        my_file = Path("./trainingmodel.yml")

        if my_file.is_file():
            self.recognizer.read('./trainingmodel.yml')
            print('Training Data Loaded !\n')
        else:
            print('No training File exists')

        self.font = cv2.FONT_HERSHEY_PLAIN

    def openDialogWindow(self):
        Dialog = QtWidgets.QDialog()
        ui = Ui_Dialog()
        ui.setupUi(Dialog)
        Dialog.show()
        response = Dialog.exec_()

        if response == QtWidgets.QDialog.Accepted:
            self.Dialogtext = ui.lineEdit.text()
            # print( self.Dialogtext)
            if  self.Dialogtext:
                print(self.Dialogtext)
                self.CreateNewPersonData(self.Dialogtext)
            else:
                print("No variable set")
        else:
            print("No variable set")

    def CreateNewPersonData(self, personName):
        path = 'dataset'
        folderPath = [os.path.join(path, f) for f in os.listdir(path)]
        numfolders = len(folderPath)
        newfoldername = str(numfolders + 1) + '.' + personName
        print(newfoldername)
        finalpath = os.path.join(path, newfoldername)
        print(finalpath)
        os.mkdir(finalpath)

        self.capture = cv2.VideoCapture(0)
        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)

        for i in range(50):
            ret, self.image = self.capture.read()
            self.image = cv2.flip(self.image, 1)
            self.DisplayImage(self.image, 1)
            imagename = os.path.join(finalpath, 'capture' + str(i) + '.jpg ')
            cv2.imwrite(imagename, self.image)

        self.capture.release()
        del(self.capture)
        cv2.destroyAllWindows()

    @pyqtSlot()
    def OpenSerialPort(self):
        self.SerialThread.start()

    def sendData(self, buff):
        self.serialWrite.emit(buff)

    @pyqtSlot()
    def CloseSerialPort(self):
        if (self.SerialThread.isRunning()):
            self.SerialThread.Close_Serial()
            self.SerialThread.terminate()

    @pyqtSlot()
    def addNewPersonClicked(self):
        self.openDialogWindow()

    @pyqtSlot()
    def trainClicked(self):
        path = 'dataset'
        faceSamples = []
        ids = []
        id = []
        names = []
        imagePath = [os.path.join(path, f) for f in os.listdir(path)]

        for imagePath in imagePath:
            tempid = os.path.split(imagePath)
            person_id = tempid[1]
            retval = person_id.split('.')

            names.append(retval[1])

            # print(person_id)

            filelist = os.listdir(imagePath)
            print(filelist)

            for imgfilename in filelist:
                imgfilenamewithpath = os.path.join(imagePath, imgfilename)
                print(imgfilenamewithpath)

                PIL_img = Image.open(imgfilenamewithpath).convert('L')
                img_numpy = np.array(PIL_img, 'uint8')

                faces = self.faceCascade.detectMultiScale(img_numpy)

                for (x, y, w, h) in faces:
                    self.image = cv2.imread(imgfilenamewithpath)
                    cv2.rectangle(self.image, (x - 20, y - 20), (x + w + 20, y + h + 20), (10, 255, 10), 4)
                    self.DisplayImage(self.image, 1)
                    # time.sleep(1)
                    faceSamples.append(img_numpy[y:y + h, x:x + w])
                    # ids.append(int(person_id))
                    id.append(int(retval[0]))

        self.recognizer.train(faceSamples, np.array(id))
        self.recognizer.write('trainingmodel.yml')

        with open('trainlabelnames.pkl','wb') as f:
            pickle.dump(names,f)

    @pyqtSlot()
    def takePhotoClicked(self):
        ret, self.image = self.capture.read()
        self.image = cv2.flip(self.image, 1)
        self.stopCameraClicked()
        self.DisplayImage(self.image, 1)

    @pyqtSlot()
    def openCameraClicked(self):
        self.capture = cv2.VideoCapture(0)
        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)

        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(5)

    def update_frame(self):
        ret, self.image = self.capture.read()
        self.image = cv2.flip(self.image, 1)
        self.DisplayImage(self.image, 1)

    @pyqtSlot()
    def stopCameraClicked(self):
        self.timer.stop()
        self.capture.release()

    def LoadImageFunction(self, fname):
        self.image = cv2.imread(fname)
        self.DisplayImage(self.image, 1)

    def DisplayImage(self, img, window=1):
        qformat = QImage.Format_Indexed8
        if len(img.shape) == 3:
            if (img.shape[2]) == 4:
                qformat = QImage.Format_RGBA8888
            else:
                qformat = QImage.Format_RGB888

        outImg = QImage(img, img.shape[1], img.shape[0], img.strides[0], qformat)

        outImg = outImg.rgbSwapped()

        if window == 1:
            self.imgLabel.setPixmap(QPixmap.fromImage(outImg))
            self.imgLabel.setAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
            self.imgLabel.setScaledContents(True)

    @pyqtSlot()
    def RecogniseFace(self):
        self.DetectFacesFunction(self.image)

    def DetectFacesFunction(self, img):

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = self.faceCascade.detectMultiScale(gray, 1.2, 5, minSize=(90, 90))

        if len(faces) is not 0:

            for (x, y, w, h) in faces:

                # Recognize the face belongs to which ID
                person_id, confidence = self.recognizer.predict(gray[y:y + h, x:x + w])
                persons_list = []
                persons_list.append(person_id)
                print(str(person_id))
                print(str(confidence))
                print(persons_list)

                with open('trainlabelnames.pkl', 'rb') as f:
                    names = pickle.load(f)

                if 20 < confidence < 50:
                    if person_id == 0:
                        person = "Unknown"
                        print('Unknown Person !')
                        cv2.imwrite('intruder.jpg',img[y:y + h, x:x + w])
                        # self.SendEmail()
                        self.sendData('c')
                    else:
                        person = names[person_id - 1]
                        print('Person Recognised is', person)
                        self.sendData('o')



                # If recognition confidence is above threshold, then it is Unknown

                else:
                    person = "Unknown"
                    print('Unknown Person !')
                    cv2.imwrite('intruder.jpg', img[y:y + h, x:x + w])
                    self.SendEmail()
                    self.sendData('c')

                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
                cv2.putText(img, str(person), (x, y - 10), self.font, 2, (0, 255, 0), 2)
                self.DisplayImage(img, 1)
        else:
            print("No Face Detected !")
            return

        # if(person_id > 0):
        #     QMessageBox.information(self,"Recognition Result","Person Identified")
        # else:
        #     QMessageBox.information(self, "Recognition Result", "Person Unknown")


    def SendEmail(self):

        fromaddr = "trymelater111@gmail.com"
        toaddr  = "vedicaawasthi25@gmail.com"

        msg = MIMEMultipart()
        msg['From'] = fromaddr
        msg['To'] = toaddr
        msg['Subject'] = "INTRUDER ALERT !"
        body = "We Have an Unknown person or an Intruder at the Security check."

        msg.attach(MIMEText(body, 'plain'))
        filename = "intruder.jpg"
        attachment = open(filename, "rb")
        p = MIMEBase('application', 'octet-stream')
        p.set_payload((attachment).read())
        encoders.encode_base64(p)
        p.add_header('Content-Disposition', "attachment; filename= %s" % filename)
        msg.attach(p)
        s = smtplib.SMTP('smtp.gmail.com', 587)
        s.starttls()
        s.login(fromaddr, "qwerty@123456")
        text = msg.as_string()
        s.sendmail(fromaddr, toaddr, text)
        s.quit()

    def find_Arduino_Com_Port(self):
        arduino_ports = [
            p.device
            for p in serial.tools.list_ports.comports()
            if 'Arduino' in p.description
        ]

        if not arduino_ports:
            raise IOError("No Arduino found")
        if len(arduino_ports) > 1:
            warnings.warn('Multiple Arduinos found - using the first')

        port_str = arduino_ports[0]
        return port_str

    @pyqtSlot()
    def exitClicked(self):
        if (self.SerialThread.isRunning()):
            self.SerialThread.Close_Serial()
            self.SerialThread.terminate()
        QApplication.instance().quit()



app = QApplication(sys.argv)
window = FaceSecurityML()
window.show()
app.exec_()
